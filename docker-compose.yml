# This docker compose file assumes the ollama server is running on the host machine
# with the model llama3.2 already available
# For a version running with ollama in a container, see: docker-compose-ollama.yml
services:
  db:
    image: postgres
    ports:
      - "5432:5432"
    env_file:
      - postgres.env
    restart: always

  redis:
    image: redis:latest
    ports:
      - "6379:6379"
    restart: always

  app:
    build: .
    ports:
      - "8080:8080"
    depends_on:
      - db
      - redis
    environment:
      - SPRING_DATASOURCE_URL=jdbc:postgresql://db:5432/tunescout
      - SPRING_DATASOURCE_USERNAME=postgres
      - SPRING_DATASOURCE_PASSWORD=changemeinprod!
      - SPRING_DATA_REDIS_HOST=redis
      - SPRING_DATA_REDIS_PORT=6379
      - SPRING_AI_OLLAMA_BASE_URL=http://host.docker.internal:11434
    restart: always
